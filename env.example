# Ejemplo de variables de entorno para la aplicación FSM
# Copia este archivo a .env y ajusta los valores según tu configuración.

# --- Configuración General de Módulos ---
ENABLE_API="true" # Habilitar el servidor API (true/false)
ENABLE_ARI="true" # Habilitar el cliente ARI de Asterisk (true/false)
ENABLE_SOCKET_SERVER="true" # Habilitar el servidor de sockets UNIX (true/false)

# --- Configuración del Servidor API (si ENABLE_API="true") ---
PORT=3000 # Puerto en el que escuchará el servidor API
API_JSON_PAYLOAD_LIMIT="1mb" # Límite para payloads JSON
API_TEXT_PAYLOAD_LIMIT="1mb" # Límite para payloads de texto plano

# --- Configuración del Servidor de Sockets (si ENABLE_SOCKET_SERVER="true") ---
FSM_SOCKET_PATH="/tmp/fsm_service.sock" # Ruta para el archivo de socket UNIX

# --- Configuración de la FSM ---
DEFAULT_INTENT="intent_schedule_appointment" # ej: intent_schedule_appointment. Intención por defecto si no se provee ninguna. Dejar vacío para no asumir.
REDIS_SESSION_TTL=3600 # Tiempo de vida de la sesión en Redis (en segundos). 0 o vacío para sin expiración.

# --- Configuración de Logging ---
LOG_LEVEL="info" # Nivel de log (fatal, error, warn, info, debug, trace). 'debug' en desarrollo, 'info' en producción.
NODE_ENV="development" # Define el entorno (development, production). Impacta el formato del log.

# --- Configuración de Redis ---
REDIS_HOST="127.0.0.1"
REDIS_PORT=6379
# REDIS_USER="" # Descomentar si Redis requiere autenticación de usuario (para Redis 6+)
REDIS_PASSWORD="" # Descomentar y establecer si Redis requiere contraseña
REDIS_DB=0 # Número de la base de datos Redis a usar
SIMULATOR_STREAM_MAXLEN=1000 # Longitud máxima aproximada para streams creados por simulateApiResponder.js

# --- Configuración de Asterisk ARI (si ENABLE_ARI="true") ---
ARI_APP_NAME="fsm-ari-app" # Nombre de la aplicación Stasis en Asterisk
ARI_USERNAME="ariuser"
ARI_PASSWORD="aripass"
ARI_URL="http://localhost:8088" # URL base del servidor ARI (ej: http://asterisk_ip:8088)

# --- Configuración del Servicio de IA ---
AI_PROVIDER="openai" # Proveedor de IA a usar ('openai', 'google', 'groq')
AI_REQUEST_TIMEOUT="10000" # Timeout en milisegundos para las solicitudes a la IA (default: 10000ms = 10s)

# --- OpenAI ---
OPENAI_API_KEY="" # Tu clave API de OpenAI
OPENAI_MODEL="gpt-3.5-turbo" # Modelo de OpenAI a usar
OPENAI_TEMPERATURE="0.7" # Temperatura para las respuestas de OpenAI

# --- Google Gemini ---
GEMINI_API_KEY="" # Tu clave API de Google Gemini
GEMINI_MODEL="gemini-pro" # Modelo de Gemini a usar
# GEMINI_TEMPERATURE="0.7" # Gemini API puede no tener un param de temperatura directo en todas las SDKs, ajustar en prompt si es necesario

# --- Groq ---
GROQ_API_KEY="" # Tu clave API de Groq
GROQ_MODEL="mixtral-8x7b-32768" # Modelo de Groq a usar (e.g., 'mixtral-8x7b-32768', 'llama2-70b-4096')
GROQ_TEMPERATURE="0.7" # Temperatura para las respuestas de Groq
